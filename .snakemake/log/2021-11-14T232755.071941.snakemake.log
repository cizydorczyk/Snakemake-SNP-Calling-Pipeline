Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job            count    min threads    max threads
-----------  -------  -------------  -------------
all                1              1              1
remove_seqs        1              1              1
total              2              1              1

Select jobs to execute...

[Sun Nov 14 23:27:55 2021]
rule remove_seqs:
    input: /home/conrad/test-snakemake/snippy-core/12.clean.full.aln
    output: /home/conrad/test-snakemake/snippy-core/12.no_ref.clean.full.aln, /home/conrad/test-snakemake/snippy-core/12.no_ref_no_outgroups.clean.full.aln
    jobid: 8
    wildcards: output=/home/conrad/test-snakemake/, st=12
    resources: tmpdir=/tmp

/home/conrad/anaconda3/envs/i18_snp_pipeline_env_testing/bin/python3.7 /home/conrad/test-snakemake/.snakemake/scripts/tmpdw1oz43b.remove_seqs_function.py
[Sun Nov 14 23:27:55 2021]
Finished job 8.
1 of 2 steps (50%) done
Select jobs to execute...

[Sun Nov 14 23:27:55 2021]
localrule all:
    input: /home/conrad/test-snakemake/raw-snippy-output/A077-H36-15-04-2009, /home/conrad/test-snakemake/raw-snippy-output/A077-H138-28-05-2009, /home/conrad/test-snakemake/raw-snippy-output/A077-H201-11-05-2009, /home/conrad/test-snakemake/raw-snippy-output/A013-H12-09-07-2003, /home/conrad/test-snakemake/raw-snippy-output/A077-H202-25-05-2009, /home/conrad/test-snakemake/snippy-core/12.full.aln, /home/conrad/test-snakemake/snippy-core/12.clean.full.aln, /home/conrad/test-snakemake/snippy-core/12.no_ref.clean.full.aln, /home/conrad/test-snakemake/snippy-core/12.no_ref_no_outgroups.clean.full.aln
    jobid: 0
    resources: tmpdir=/tmp

[Sun Nov 14 23:27:55 2021]
Finished job 0.
2 of 2 steps (100%) done
Complete log: /home/conrad/test-snakemake/.snakemake/log/2021-11-14T232755.071941.snakemake.log
